# SQL (Relational)

>[!Note]- When to use Relational Database
> <!-- Multiline -->
> 1. **~={purple}Structured Data=~**: Data follows a schema with strict requirements.
> 2. **~={purple}ACID=~**: NoSQL may not support ACID.
> 3. **~={purple}Scalability=~**: SQL databases scale vertically, usually on a single server. Cloud storage can be used however it's still difficult with ACID being maintained.
> 4. **~={purple}Frequent Joins=~**: Can you SQL to involve data from multiple tables.
> 

>[!Note]- What is an RDBMS?
> <!-- Multiline -->
>* **~={purple}Stored on Disk=~**: We want the data to be persisted
>* **~={purple}Data Structure=~**: B+ Tree is used for RDBMS indexing. It is an index for the actual data stored on disk, where the B+ Tree is loaded into memory upon an SQL query.
>	* Each node has $m$ children. 
>		* **~={green}Internal Nodes=~**: Stores $(key, pointer)$, where the pointers point to children nodes
>		* **~={green}Leaf Nodes=~**: Stores $(key, pointer)$, where the pointer points to a data record (Row in SQL Table). Th
>		
> ![[Drawing 2025-02-04 08.08.31.excalidraw | center | 700]]

>[!Note]- What is ACID?
> <!-- Multiline -->
>1. **~={red}Durability=~**: RDBMS is stored on disk. Every transaction that is made which is **~={blue}committed=~**, then it should be persisted.
>2. **~={red}Atomicity=~**: Transactions are performed **~={blue}in it's entirety=~**, or not at all. (A transaction is X number of SQL queries)
>3. **~={red}Isolation=~**: When we have multiple transactions happening concurrently, we want them to appear as if transactions are **~={blue}happening in order=~**. This means we want the schedule of transactions to be **~={green}serialisable=~**. (i.e. T1 -> T2, rather then T1 & T2)
>4. **~={red}Consistency Prevention=~**: Takes the database from one **~={blue}consistent state=~** to another **~={blue}consistent state=~**. A consistent state is a state that follows all constraints set by our RDBMS (i.e. column $x$ needs to be unique, foreign keys maintained)
> 

>[!Note]- What happens if Isolation and Consistency aren't met?
> <!-- Multiline -->
> * **~={blue}A Write Operation=~**: Updates the value on the disk
> * **~={blue}Commit Operation=~**: Makes the change permanent
>5. **~={red}Lost Update=~**:
>````col
>```col-md
> ![[Drawing 2025-02-05 08.10.23.excalidraw | center | 450]]
>```
>```col-md
>* T1 Updates X
>* T2 Updates X
>* T1 Changes are Written to the Disk
>* T2 Changes are Written to the Disk without accounting for T1's Changes
>```
>````
>6. **~={red}Dirty Read=~**:
>````col
>```col-md
>![[Drawing 2025-02-04 08.34.07.excalidraw | center | 450]]
>```
>```col-md
>* T1 Updates X
>* T2 Reads Updated X
>* T1 Fails for Some Reason. Hence the value that T2 read is no longer correct.
>```
>````
> 
>7. **~={red}Unrepeatable Read=~**:
>````col
>```col-md
> ![[Drawing 2025-02-05 08.15.50.excalidraw | center | 450]]
>```
>```col-md
>* T1 and T2 Read X
>* T1 Updates X
>* T2 Reads X
>* T2 read X twice in the same transaction but it yielded a different value each time. This should not happen.
>```
>````
>8. **~={red}Phantom Read=~**:
>````col
>```col-md
> ![[Drawing 2025-02-05 08.27.56.excalidraw | center | 450]]
>```
>```col-md
>* T1 and T2 Read X
>* T1 Deletes X
>* T2 Reads X
>* T2 Reads X, but the value has now been deleted leading to an error
>```
>````

>[!Note]- Isolation Levels
> <!-- Multiline -->
> There are a few isolation levels that can be set on a database:
> 
> ![[Drawing 2025-02-05 09.02.27.excalidraw | center | 600]]
>

>[!Note]- Writing vs Committing in Transactions
> <!-- Multiline -->
> Only when an update has been committed can other transactions read the updated value that your transactions caused.
>

>[!Note]- Concurrency Control Mechanisms: Pessimistic Concurrency Control
> <!-- Multiline -->
> **~={blue}Traits=~**:
> * Pessimistic locking works by **locking rows or tables** to prevent concurrent transactions from modifying data in conflicting ways. It ensures data integrity by **blocking other transactions until the current one completes**.
> * **~={green}Shared Lock=~**: Read Lock
> * **~={red}Exclusive Lock=~**: Write Lock
> 
> ![[Drawing 2025-02-05 13.32.11.excalidraw | center | 300]]
> **~={blue}How it Prevents=~**:
>9. **~={red}Lost Update=~**:
>````col
>```col-md
>**~={green}With Pessimistic Locking=~**
> ![[Drawing 2025-02-05 13.02.51.excalidraw]]
>
>```
>```col-md
>**~={red}Why it Works=~**
>* **~={blue}Exclusive Lock=~**: Prevents T2 from reading and updating data that T1 has an exclusive lock on. Hence we cannot write to stale data.
>* **~={red}Ensures only one transaction modifies a row at a time.=~**
>```
>````
>10. **~={red}Dirty Read=~**:
>````col
>```col-md
> ![[Drawing 2025-02-05 13.10.31.excalidraw]]
>```
>```col-md
>**~={red}Why it Works=~**
>* **~={blue}Exclusive Lock=~**: Prevents T2 from reading data that T1 has an exclusive lock on. Hence, we cannot read stale data.
>* **~={red}Prevents reading uncommitted changes.=~**
>```
>````
> 
>11. **~={red}Unrepeatable Read=~**:
>````col
>```col-md
> ![[Drawing 2025-02-05 13.16.02.excalidraw]]
>```
>```col-md
>**~={red}Why it Works=~**
>* **~={blue}Shared Lock=~**: Prevents T2 from modifying data T1 is currently reading/has a shared lock on. Hence, when T1 re-reads that value, it remains the same.
>* **~={red}Ensures a row cannot change while being read.=~**
>```
>````
>12. **~={red}Phantom Read=~**:
>````col
>```col-md
> ![[Drawing 2025-02-05 13.28.56.excalidraw]]
>```
>```col-md
>* **~={blue}Shared Lock=~**: Prevents T2 from deleting data T1 is currently reading/has a shared lock on.
>* **~={red}Prevents new rows or deleted rows from appearing in a repeated read.=~**
>```
>````

>[!Note]- Concurrency Control Mechanisms: Optimistic Concurrency Control
> <!-- Multiline -->
> **~={blue}Traits=~**:
> * Optimistic Concurrency Control **(OCC)** allows transactions to proceed **without locking** but performs **validation before commit** to detect conflicts. If a conflict is detected, the transaction **rolls back and retries**.
> * It works on a local copy of data, and updates the database afterwards.
> * Each table now has a `version` column
> 
> **~={blue}How Versioning Works=~**:
> * If we read a value, the version of that values remains the same
> * If we update a value, we re-read the value to check if the version we read matches, if so, we update the value
> * If the version was a mismatch, the update will have failed, and it will be reattempted by re-reading and re-writing
>
> **~={blue}How it Prevents=~**:
>13. **~={red}Lost Update=~**:
>````col
>```col-md
>**~={green}With Pessimistic Locking=~**
> ![[Drawing 2025-02-05 13.41.46.excalidraw]]
>
>```
>```col-md
>**~={red}Why it Works=~**
>* It ensures a transaction will fail if another transaction modifies the same row another has already modified.
>* **~={red}Ensures only one transaction modifies a row at a time.=~**
>```
>````
>14. **~={red}Dirty Read=~**:
>````col
>```col-md
> ![[Drawing 2025-02-06 16.38.57.excalidraw]]
>```
>```col-md
>**~={red}Why it Works=~**
>* **~={red}Prevents reading uncommitted changes.=~**
>```
>````
> 
> 3. **~={red}Unrepeatable Reads=~**: Is not prevented as rows are not locked, so other transactions can modify the same row before a second read.
> 4. **~={red}Phantom Read=~**: Is not prevented as tables are not locked, so other transactions can insert or delete rows concurrently.

>[!Note]- Deadlock Prevention For Pessimistic Concurrency Control
> <!-- Multiline -->
>15. **~={red}Wait Die Scheme=~**:
>````col
>```col-md
>
> ![[Drawing 2025-02-06 17.05.42.excalidraw]]
>```
>```col-md
>* **Older** transactions can **wait** if a younger transaction holds the lock they need. **~={red}Older will wait.=~**
>* If a **younger** transaction requests a lock held by an older transaction, the younger transaction is **aborted** (it “dies”) to prevent deadlock. **~={red}Younger dies if requesting lock.=~**
>```
>````
>16. **~={red}Wound Wait=~**:
>````col
>```col-md
>
> ![[Drawing 2025-02-06 17.09.27.excalidraw]]
>```
>```col-md
>* Older transactions do **not wait** if a younger transaction holds the lock they need; instead, the younger transaction is “wounded” (aborted) to free the lock. **~={red}Older kills if needs to.=~**
>* If a **younger** transaction requests a lock held by an older transaction, the younger transaction **waits** until the older transaction releases it. **~={red}Younger waits if requesting lock.=~**
>```
>````
>Both cases can cause **~={green}starvation=~** of younger transactions, causing them to never occur

# NoSQL (Non Relational)

>[!Note]- Document Database
> <!-- Multiline -->
> ~={blue}**How it Works**=~
> * Stores data as **JSON-like documents** rather than rows and columns.
> * Documents are **self-contained** and map directly to objects in code, eliminating the need for expensive joins.
> 
> **~={blue}What it's Good At=~**
> * ~={green}**Flexibility=~:** Schema can change dynamically.
>
> ~={red}**Example**=~
>```json
>{
>    "name": "John Doe",
>    "email": "john.doe@example.com",
>    "experience": [
>        {
>            "company": "TechCorp",
>            "role": "Software Engineer",
>            "years": 3
>        },
>        {
>            "company": "InnovateX",
>            "role": "Senior Developer",
>            "years": 2
>        }
>    ],
>    "skills": ["Java", "Python", "MongoDB"]
>}
>```

>[!Note]- Graph Database
> <!-- Multiline -->
> ~={blue}**How it Works**=~
> * A **graph database** uses **~={green}nodes=~**, **~={green}edges=~**, and ~={green}**properties**=~ to store data.
> 
> **~={blue}What it's Good At=~**
> * ~={green}**Relationship Based Queries=~:** Optimised for relationship based queries such as "Who are my friends"
>
> ~={red}**Example**=~
>```css
(:User {id: 1, name: "Alice"})
(:User {id: 2, name: "Bob"})
(:User {id: 3, name: "Charlie"})
>
>(:User {id: 1})-[:FRIENDS_WITH]->(:User {id: 2})
>(:User {id: 2})-[:FRIENDS_WITH]->(:User {id: 3})

>[!Note]- Column Store
> <!-- Multiline -->
> ~={blue}**How it Works**=~
> * A **column store** organises data **by ~={green}columns=~ instead of rows**
> 
> **~={blue}What it's Good At=~**
> * ~={green}**Analytical Queries=~:** Makes analytical queries much faster as we only require relevant columns (Queries like **"SUM(Price)"** only read the **Price** column, improving efficiency.)
>
> ~={red}**Example**=~
> 1. **~={red}Row Based Storage=~**
>```markdown
>OrderID | Customer | Product | Price | Quantity
>------------------------------------------------
>101     | Alice    | Laptop  | 1200  | 1
>102     | Bob      | Mouse   | 25    | 2
>103     | Charlie  | Keyboard| 45    | 1
>```
>
> 2. **~={red}Column Based Storage=~**
>```mathematica
>Column: OrderID    [101, 102, 103]
>Column: Customer   ["Alice", "Bob", "Charlie"]
>Column: Product    ["Laptop", "Mouse", "Keyboard"]
>Column: Price      [1200, 25, 45]
>Column: Quantity   [1, 2, 1]

> [!Note]- Key Value Store: Log-Structured Storage (LSM)
> 
> ~={blue}**How it Works**=~
> 
> - An **LSM Tree** is designed for ~={green}**high-write workloads**=~, storing key value pairs, optimising performance by **first writing data to memory** before flushing it to disk in a **sorted manner**.
> ---
> - **~={green}Writes=~:** 
> 	1. Data is **appended to an in-memory structure** (typically a **balanced tree like an AVL tree**).
> 	2. **~={green}Flushing=~:** When the memory table fills up, it is **flushed to disk** as an **SSTable (Sorted String Table)**.
> 	3. **~={green}Compaction=~:** SSTables are periodically **merged** to improve **query efficiency and storage space**. (Merge older ones so there are less SSTables to search, reducing disk I/O access.)
> 
> ~={blue}**What it's Good At**=~
> 
> - **~={green}Write Performance=~:** Efficient for **high insert rates**, as it writes data **sequentially** instead of modifying existing disk structures.
> - **~={green}Efficient Reads=~:** Uses **sorted** SSTables and **bloom filters** to speed up lookups.
> 
> **~={red}Example=~**
> 
> 1. ~={red}**Memory Table (Before Flushing to Disk)**=~
> * Store Key Value Pairs
> 
> ```markdown
> Key       | Value  
> -----------------
> sensor_1  | 24.5°C  
> sensor_2  | 22.1°C  
> sensor_3  | 25.0°C  
> ```
> 
> - When full, this is written to an **SSTable on disk**.
>     
> 
> 3. ~={red}**SSTable (Sorted String Table on Disk)**=~
> 
> ```mathematica
> Key       Value
> -----------------
> sensor_1  24.5°C
> sensor_2  22.1°C
> sensor_3  25.0°C
> ```
> 
> - Multiple SSTables exist at different levels and are merged periodically for **efficiency**. An LSM tree manages SSTables.

> [!Note]- Bloom Filter (Used in LSM Trees)
> 
> ~={blue}**How it Works**=~
> 
> - A **bloom filter** is a **probabilistic data structure** used to **quickly check if a key might exist** in an LSM Tree before performing a **disk lookup**.
> - ~={green}**Insertion=~:** Each key is hashed using **multiple ($n$) hash functions**, setting corresponding bits in a **bit array**.
> - ~={green}**Lookup=~:**
>     - If **any bit is 0**, the key **definitely does not exist**.
>     - If **all bits are 1**, the key **might exist**, so the system checks disk storage.
> - Helps avoid **unnecessary disk reads**, improving read performance.
> 
>  ![[Drawing 2025-02-06 20.32.32.excalidraw | center | 600]]
> 
> ~={blue}**What it's Good At**=~
> 
> - ~={green}**Reducing Disk Reads=~:** Prevents unnecessary lookups by quickly determining if data **might exist**.
> - **~={green}Low Memory Usage=~:** Uses a **compact bit array** instead of a full index, making it **memory-efficient**.
> 
> ~={red}**Example**=~
> 
> 4.~={red} **Bloom Filter Bit Array**=~
> 
> ```mathematica
> 0000000000000000  (Initial)
> 1010001000000100  (After inserting "sensor_1", "sensor_2", and "sensor_3")
> ```
> 
> - Each **bit position** corresponds to a **hash function output**.
>     
> 
> 1. ~={red}**False Positives & False Negatives**=~
> 
> - ~={green}**False Positives=~:** Yes, different keys may **collide**, causing a key that **was never inserted** to be mistakenly marked as present.
> - ~={green}**False Negatives=~:** No, if a Bloom filter says **"not found"**, then the key is **definitely not present** (guaranteed).

>[!Note]- NoSQL: Eventual Consistency
> <!-- Multiline -->
> We can split up databases with SQL too (sharding), though it's easier with NoSQL and sharding is possible by default. The following is a replication example:
> 
> ![[Drawing 2025-02-06 20.41.24.excalidraw | center | 650]]
> 
> 
>

# Database Replication

>[!Note]- Database Replication
> <!-- Multiline -->
> 
> ![[Pasted image 20250206212051.png | center | 450]]
> **~={green}Primary Database=~**
> * ~={red}Write Operations=~: Only support servers writing to it. All data operations must go through the primary database, and the primary database will write to all replicas.
> 
> **~={green}Replica Database=~**
> * ~={red}Read Operations=~: Only supports servers reading from it. 
> 
> ~={blue}**Purpose of Database Replication**=~
> 1. ~={red}Better Performance=~: Because we have multiple replica databases, it allows more read queries to be executed in parallel
> 2. ~={red}Reliability and Availability=~: If on replica stops working, the data is still persevered in other replicas and still accessible
> 
> **~={blue}If the Primary Database goes Offline=~**
> * A replica database will be promoted to the primary database. This can be difficult as the replica database may not be up to date, and thus somehow needs to become up to date.
> 
> **~={blue}If all Replica Database Poofed=~**
> * All read queries will be directed to the primary database temporarily until a new replica database is added.

# Database Scaling

>[!Note]- Vertical Scaling
> <!-- Multiline -->
> * Add more CPU, RAM, DISK to an existing database server

>[!Note]- Horizontal Scaling
> <!-- Multiline -->
> **~={blue}Sharding (Adding more Servers)=~**
> * Sharding is the idea of separating large databases into smaller parts call shards
> * ~={green}Shards=~: Each shard shares the same schema, though the actual data on each shard is unique to the shard.
> 	* **~={green}Sharding Key=~**: Allows us to retrieve and modify data by routing database queries to the correct shard. It needs to be able to evenly distribute data.
> 
> ![[Drawing 2025-02-06 21.55.01.excalidraw | center | 500]]
> 
> **~={red}Challenges=~**
> * ~={green}Resharding Data=~: If a shard has reached full capacity, we now need to update the hashing function, and move data around. This can be achieved using consistent hashing.
> * **~={green}Celebrity Problem=~**: Excessive access to a certain shard. A celebrity may receive too many read requests to a particular shard. This can be solved by giving each celebrity it's own shard. 
> * **~={green}Join and Denormalisation=~**: Once a database has been shared, for SQL databases it is hard to perform join operations across shards. To solve this, we can denormalise the database so that queries can performed in a single table.
> 	* Let's say we were joining table A and B frequently. Put the data of table B in a column in table A as a JSON string. So when we access the shard with table A, we don't need to join.
>* **~={green}Replication=~**: Each shard is it's own "primary" shard, which has replicas. We write to these primary shards that write to the replicas.
> 

#flashcards/sysdesign/concepts/databases